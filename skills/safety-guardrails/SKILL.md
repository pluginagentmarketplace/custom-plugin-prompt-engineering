---
name: safety-guardrails
description: LLM safety guardrails and content moderation
sasmp_version: "1.3.0"
bonded_agent: 08-prompt-security-agent
bond_type: PRIMARY_BOND
---

# Safety Guardrails Skill

## Overview
Implement safety guardrails and content moderation for LLM applications.

## Topics Covered

### Content Filtering
- Harmful content detection
- Profanity filtering
- Hate speech detection
- Violence prevention
- Adult content blocking

### Output Validation
- Factuality checking
- Hallucination detection
- Format validation
- Length constraints
- Topic boundaries

### Input Sanitization
- User input cleaning
- Special character handling
- Context isolation
- Prompt sanitization
- Character limits

### Moderation Systems
- Automated moderation
- Human-in-the-loop
- Appeal processes
- Escalation policies
- Feedback loops

## Prerequisites
- LLM fundamentals
- Content policy understanding

## Learning Outcomes
- Build content filters
- Implement moderation
- Validate outputs
- Design safe systems
